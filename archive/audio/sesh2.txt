

“Let’s go, here’s how the mempool is built at the server level. Essentially, how the mempool is constructed at the level of the server machine. It takes incoming requests that are either directed to sub-machines or executed in the context of the same server machine, just like everything further down in the hierarchy.  
 
So, the mempool is a set of Ether values encoded in RLP, taken from a set of keys by `bytes32` array, followed by an array of values that need to be passed according to these keys. For example, if there are 5 keys and 7 values, then the first 5 values are directed to the next sub-machines, in this case to the signers, and the last 2 are transactions executed in the context of the same machine, that is, machine-level transactions. For example, creating a new signer.  
 
So, our task is first to deal with transactions at the machine’s own level—let’s say a simple counter increment by 1, the only transactions we have. That is, we run the server machine and artificially create a transaction to increment the counter every 100 milliseconds. Then, running a timeout loop, the so-called “proposer loop” for the server machine, it creates this block with the incrementing transaction every 100 milliseconds.  
 
Accordingly, the block structure is a reference to the previous block, a set of these transactions in the form of the mempool (a single long buffer string), and the state hash that contains the content of all sub-machines plus the state of the machine itself. This is all written into LevelDB under the block number, or more precisely, under the block hash, and also saved in the machine’s root. The machine’s root is stored under the server’s ID key—here it’s just `0` in LevelDB—while the value is the RLP-encoded state of the machine in the form of the latest block.  
 
By the way, in this case there’s no real “end” to the block; we just have our own final block. The last finalized block is the machine’s root in this scenario.  
 
OK, so we have a server that’s running. How do messages arrive to it? Something must be sent to it, right? Messages come in via WebSocket, but during simulation we can just simulate the creation of various timeout messages from outside.  
 
So, messages can come to the server from a user via a user-wallet, i.e., a wallet with a special token, in which case they are considered authorized. It can also receive messages directed at specific entities.  
 
Look, so far we didn’t have a user entity—like, it comes in from an entity if it’s through a wallet. Right now we’re just talking about the counter.  
 
Yes, I understand, I understand. It’s just... where do signers appear here? Server, signers... Right. The server receives everything from outside; it accumulates messages. The signer receives messages from the user-wallet, meaning you tell the signer, “I want to…”  
 
So look, we have a server, and I’m just a regular user. How do I initiate a transaction so that something changes in the state—like a payment logic or the counter? Let’s keep it simple: the counter. I want to increment the global counter.  
 
The counter is already implemented in the context of the application in JavaScript, in this index file, on the server?  
 
Right. It just counts blocks. You mean that counter?  
 
No, I’m referring to a transaction in the form of a counter, just an incrementer.  
 
OK, OK, OK. So we’ll implement just this one. At this point, it’s the server file itself, our minimal MVP. In reality, transactions will be initiated either by the user-wallet with a token (a local HTML in the browser that interacts with the server daemons), or in real operation we might have my personal counter on the server. I, as a user, want to increment that counter on the server.  
 
You mean a signer’s counter?  
 
Yes, just send a message: “Do something.” Then we’d have two layers of abstraction straight away: the server and the signer.  
 
In principle, we can do that right away, sure.  
 
That’s the next step though. Right now, the counter can be on any machine level.  
 
You target it from outside by choosing which machine level you’re coming into. The function—be it `WebSocketServer.onReceiveMessage` or manually invoked—just receives who sent it (some other signer, another server— we know that) and some other entity type indicating its origin. It’s also directed somewhere inside my signer, inside my server, to one of my entities. This is an external message.  
 
I might have asked incorrectly, but look, it can be the case that I’m a regular user and I have a wallet, and in that wallet I want to increment the counter, just to...  
 
Right, that’s already the next level—an entity. I mean, as a user, who am I connecting to? Where do I send the message as a user?  
 
You’d also send it to this WebSocket with a target, with a route...  
 
To whom am I sending it?  
 
To the server, because everything that comes in always enters via the server, and from there it’s routed to the producer or to other signers or entities or channels. Then it gathers them all with `Promise.all`.  
 
Right, got it. So I, as a user, just have a private key, and I’ll send some…  
 
Well, an API token, which the console provides to you, and it’s also stored in memory. So as a user, you can create a machine-level transaction or a signer-level transaction. The higher up the machine, the greater your access control over everything else, and the higher priority your request can have. External entities can only interact with `entities`, or at the entity creation stage they can interact with signers.  
 
Oh, so the assumption is that you’re an authorized user, and your authorization doesn’t involve private keys?  
 
Right, it’s an API token. When you add your transaction to the mempool using that API token, the system checks if you’re allowed into that queue. And that queue, the mempool, is hierarchical: there are keys for the next level, values for the next level. You could stuff it all into a single string, you get what I mean? Keys, values, plus the value for the entity itself—no key needed. Then in real time you decode it all with RLP—a simple function that either encodes or decodes buffers—and based on these keys you send everything to the signers in parallel with `Promise.all`. Meanwhile, you start processing your own items in the same moment, one after the other.  
 
Our task now, ignoring these key-value pairs, is just to do everything at the server machine level: `counter++`—like `+5`, `+6`, `+7`—and the state simply increments a number. We can store the state as a simple JSON, or maybe as an RLP-encoded number (the zero-th integer). Step zero: we just do the state in a straightforward manner, no signatures required. Right now we don’t need them at the server level. Because where do you need signatures? At least at the entity level. Even the signer might not need them because what would you be signing? Only in a situation where someone else replicates your blocks and executes them. But the signer doesn’t really need replication. Entities do that.  
 
Right, so we gather this “primitive stuff” that doesn’t verify anything—it’s just... for the first two levels, basically no signatures.  
 
Yes, I’m just saying we’ll add them later. Next, we’ll add blocks, then add signatures.  
 
Right, that’s a security layer we can add anytime. Let’s forget signatures for now and just…  
 
OK, got it. So first blocks without signatures, and then add signatures.  
 
Exactly, everything is trust-based at first. We’ll check everything 10 times later in the logic.  
 
Great. The most interesting part that I really want to finish—and then I’ll say “the hardest part is done”—is the aggregated signature. I want a place in the code logic for “sign” and “verify” for a typical user, but also at the moment where the same entity re-generates. And when you have 10 users, and you’re operating as an operator, as a proposer, you’re not just making a single signature, but you’re plugging your signature into your slot in this aggregated signature, also collecting it in pre-commits. So you end up with all the outgoing transactions, all the hashes that you’re sending to a depository or further. Or you’re generating blocks for channels. That’s the final layer of virtualization: if something happens in an entity, it decides to do something with channels. In parallel with sending a block, you also send signatures related to those channels, but they’re not stored inside the block itself because that would create a double loop.  
 
You see why? If you have 10 users and need a group signature for some change, you already decided to make a payment. You send out to those 10, “I propose such-and-such block. Give me your pre-commits.” They return their pre-commits and signatures for all the outgoing hashes in the deposit or further. They all verify the transactions that go into the channels. If your channel is in the “ready” state—because there are two possible channel states, “ready,” meaning you can send now, or if you’ve already sent a block you’re waiting for an acknowledgment, you can’t send now. It’s like a SYN/ACK. So you have a set of hashes that need signing, which are specifically these proposals in channels that were “ready.” They need to be signed, too. So they return them together with the pre-commit, so you end up with 10 messages, 10 channels, all signed right away. Because otherwise, you’d have to send them a hash separately and do another round trip, which is slow. We want to optimize for a really fast hub. So effectively, the flow might be: a request comes to the hub from four data centers, it immediately sends out to the other three, they return their signatures along with signatures for the subsequent channel messages (since it’s a payment, for example, union), and it broadcasts it further after doing a batch in LevelDB. Then the server mempools get them—once every 100 ms, bang.  
 
And this is where I came up with “egg agents”—the idea that all participants in the group signature need to be online. The finalization of these signatures should happen fairly quickly. It’s neat that in certain cases (not 100% of them), you can just have an “accountant” agent who’s like “Yes, that’s a normal procedure. Let’s pass it.”  
 
Note an important distinction: we talked about signatures on pre-commits for blocks, but there are two kinds. The transactions that hit the “global” are automatically all executed. Why? Because at the entity-management level, it’s two-tiered. Transactions do something with proposals, and only when a proposal has enough actions do we see an actual result inside the entity. Because if we allowed any single transaction to change anything, then any one of 100 owners of this entity could take it and delete it, for example. So any important changes go through the proposal system, where a quorum of that entity’s signers agrees on something, and only then—this is important to design elegantly—do we store the hash with the growing number of voting shares. Once it crosses the quorum, at the end of that block an `executeProposal` is done for all finalized proposals. (In code, we do something like `finalized_expired_proposals`, so it’s easy in a simple JSON object.) Then those proposals get executed—i.e., the private methods of this machine are invoked, which you cannot call from outside with a normal transaction, or else you’d compromise the entity. This is that two-tiered system for controlling changes in the machine’s state.  
 
OK, that’s basically it.”

---

**Second part:**

“You target from outside, choosing immediately which machine level you’re addressing. And this function—either `WebSocketServer.onReceiveMessage` or manually called—just takes who sent it to me (some other signer, another server—we know that) or some other entity type from which it originated, and it’s also directed somewhere in my signer, in my server, in one of my entities. That’s an external message.  
 
Maybe I asked incorrectly: look, it might be that I’m just a regular user, and I have a wallet, and in that wallet I want to increment the counter, just like…  
 
Right, that’s already the next level—a separate entity. I mean, I as a user, who am I logging in as? Whom do I send the message to as a user?  
 
You also send it to this WebSocket with a target, a route…  
 
To whom am I sending it?  
 
To the server. Everything incoming always goes through the server first, which then distributes it to the producer, the other signers, the entities, the channels, and so on, gathering them with `Promise.all`.  
 
Right, understood. As a user, I just have some private key, and I send…  
 
Or an API token that the console itself generates, which is also stored in memory. So as a user, you can create a server-level transaction or a signer-level one. The higher the machine’s level, the more access control you have over the rest, the higher priority you can set. External entities can only interact with entities, or at entity creation time they can interact with signers.  
 
So basically, you’re considered an authorized user, and your authorization isn’t tied to private keys?  
 
Exactly, it’s an API token. When you add your transaction to the mempool with that API token, the system checks if you’re allowed to add it to that queue. Because the queue (mempool) is hierarchical: it has keys for the next level, their corresponding values for the next level, plus values that might be for the same entity, without a key. So you can stuff it all into one line, like I mentioned—keys, values, plus values for the same entity. Then you decode it with RLP in real time. It’s just a function that encodes or decodes buffers. Based on these keys, you send all to the signers (the values) in parallel with `Promise.all`, and at the same time start processing your own items.  
 
For now, we’ll ignore those keys and values and just do everything at the server machine level: a counter plus 5, plus 6, plus 7, and the state simply increments a number. You can store the state in a simple JSON or RLP-encoded integer. Step zero is to implement the state in the simplest possible way, with no signatures. At the server level, we really don’t need signatures, because you only need to sign if someone else replicates your blocks and executes them. But signers don’t need that either, so long as you’re not replicating. We rely on entities for that.  
 
Right, so at these primitive levels we’re ignoring verification.  
 
Yeah, we’ll add them eventually. Then we’ll add blocks, and then signatures.  
 
Absolutely, it’s just a matter of security that can be added any time. Let’s do everything without signatures for now.  
 
Yeah, got it—blocks first, then signatures, only afterwards.  
 
Right, we trust everything for now, we’ll check it all ten times over later.  
 
Cool. The part that interests me the most, that I’ll feel is “the hardest part is done” once it’s finished, is the aggregated signature. I want the logic in the code to have something like `sign` and `verify` for a regular user, which is straightforward, but also in a scenario where you might re-generate from the same entity. And if you have 10 users, and you’re operating as the operator or the proposer, you’re not making just one signature, you’re basically adding your signature into your slot for this aggregated signature, collecting it in the pre-commits as well. So that you get all the outgoing transactions, all the hashes that you’re sending somewhere, or generating blocks for channels. That’s the final layer of virtualization: if the entity does something, it decides to do something with channels, so you send the block along with the signatures for those channels. But they’re not stored in the block itself because that would create a double loop.  
 
You see why? You have 10 users, you need a group signature for a certain change, you’ve decided you need to do a payment, so you send out “I propose such a block; give me your pre-commits.” They return their pre-commits and signatures for all the outgoing channel hashes, verifying those transactions are correct. If your channel is in “ready” state—there are two states, so if you’ve already sent a block and are waiting for acknowledgment, you can’t send right now. It’s like a SYN/ACK. So you have these hashes that need to be signed, which are basically the proposals to the channels that were in “ready” state. These also need to be signed. So they return them along with the pre-commit, and you get 10 messages, for instance, 10 channels, all signed at once. Otherwise, you’d have to send them the hash separately and initiate yet another round of communication. We want to optimize for a fast hub. So basically, maybe it works like this: a request comes to the hub from four data centers, the hub immediately sends out to the other three, they return signatures along with signatures for the next channel messages (like if it’s a payment union), then after writing a batch to LevelDB, it starts broadcasting. Then that hits the server mempools, which every 100 ms do a quick update, etc.  
 
And that’s where the idea of “egg agents” came in—that all participants in the group signature should be online. The finalization should be fairly quick, and it’s nice that in some cases (not all) there could be a single “accountant” agent who says, “Yes, that’s normal; let’s let it through.”  
 
Here’s an important distinction: we’ve been talking about signatures on block pre-commits, but there are two types. The transactions that got into the global set are automatically executed. Why? Because at the two-tier entity management level, transactions do something with proposals, and only when a proposal has enough actions do we see the actual effect inside the entity. Otherwise, if a single transaction could change everything, any one of 100 entity owners could just delete it, for example. So any important changes are done through the proposal system, where a quorum of the entity’s signers agrees. At that point—and we want to do this elegantly and compactly—we store a hash that accumulates a number of voting shares, and once it hits the quorum, the block’s end calls `executeProposal` on all proposals that are “finalized.” In the code, there’s something like `finalized_expired_proposals` so it’s easy to handle in a simple JSON object, and we carry out those proposals. Essentially, they are the private methods of the machine, which you can’t call from outside with a normal transaction—otherwise, that would compromise the entity. That’s the two-layer system for controlling state changes in the machine.  
 
OK, that’s probably everything.”
